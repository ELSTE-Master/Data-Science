---
title: "Intro to Pandas"
format:
  html:
    code-fold: false
    code-line-numbers: true
    css: [../assets/webex.css]
    include-after-body: [../assets/webex.js]
    embed-resources: true 
jupyter: python3
---

```{python}
#| echo: false
from pywebexercises.exercises import mcq, longmcq, torf
import matplotlib.pyplot as plt
plt.rcParams.update({
    "figure.facecolor":  (0.0, 0.0, 0.0, 0.0),  # red   with alpha = 30%
})
```

## Introduction

We will start our data science journey by learning a bit about the most useful Python library for this class: **Pandas**. As a reminder, a *library* is a set of tools we load on top of Python that provides new functionalities for a specific problem or type of analysis. Here, Pandas provides functions for **data manipulation and analysis**, handling structured data like tables or time series and facilitating numerous tasks you might encounter as a scientist. These include:

- **Reading/writing data** from various commonly-used formats (CSV, Excel, SQL, JSON, etc.)
- Handling **missing data**
- **Filtering**, **sorting**, **reshaping** and **grouping** data
- **Aggregating** data (sum, mean, count, etc.)
- **Time series support** (date ranges, frequency conversions)
- **Statistical operations**

### Today's objectives {.unnumbered}

The objective of this class is by no way to make you an expert in Pandas and data science. Rather, the objective is to take you through the most basic manipulations in order to build the confidence to keep on exploring the use of scientific coding and to include it into your research pipeline. The objectives of this module are to review:

- [x] What is a Pandas DataFrame and its basic anatomy
- [x] How to *load data* in a DataFrame
- [x] How to *access* data (e.g., query by label/position)
- [x] How to *filter* data (e.g., comparison and logical operators)
- [x] How to *rearrange* data (e.g., sorting values)
- [x] How to *operate* on data (e.g., arithmetic and string operations)

We first start by reviewing the [data structure](#pandas-data-structure) behind Pandas, then we will move on to a [coding exercise](#coding-playground) to make you familiar with some basic functionalities.

## Pandas data structure

Pandas consists of two main types of **data structures**. Let's make an analogy with Excel.

1. **Series**: A 1D labeled array. Think of a 2-columns Excel spreadsheet where the left column would contain a *label* (e.g., the time of a measurement) and the right column would contain a *value* (e.g., the actual value measured at the time specified in the label, let's say the temperature of a river).
2. **DataFrame**: A 2D labeled table. This is the same as an Excel spreadsheet that would contain more columns than a Series. You can think of having measurements of different variables contained in each column (e.g., the flow rate, the turbidity etc...).

The keyword here is **labelled**. In Excel, you might get a column using *letters* and rows using *numbers*. In Pandas, you can use the column name (e.g., `water_temperature`) or the row label (e.g., `2021-06-15 14:19:14`).


::: {.callout-note}
## DataFrame
Throughout this class we will focus on the use of **DataFrames**, not Series. Keep in mind that the behaviour between both is almost identical.
:::

### Anatomy of a DataFrame {.unnumbered}

@fig-anatomy shows the basic anatomy of a DataFrame that contains four **rows** and four **columns**). We already see some data structuring emerging:

- *Rows* tend to represent **entries**, which can be:
  - Different measurements at specific time steps
  - Different samples collected at different place/times
  - etc.
- In contrast, *column* represent **attributes** and store the properties of each entry:
  - The actual values of different measured parameters
  - The location and time of collected samples, along with associated analyses (e.g., geochemistry)
  - etc.



![Basic anatomy of a Pandas DataFrame.](img/pandas-1.png){#fig-anatomy}

The first row - i.e. the row containing the column *labels* - is not considered as an entry. This is because the **top row** of a dataframe is usually used as the *label* for the **columns**. Similarly, we might want to set the **first column** as a *label* for the **rows** (@fig-index). In a nutshell:

- **Index** refers to the label of the **rows**. In the *index*, **values are usually unique** - meaning that each entry has a different label.
- **Column** refers to the label of - logically - the **columns**

![Index and columns of a DataFrame.](img/pandas-2.png){#fig-index}

::: {#cau-indexing .callout-caution}
## Indexing in Python
Remember that in Python, indexing starts from 0 - so the first row or column has an index of 0.
:::




## Coding playground

Let's get our hands dirty and start coding. Create a new Jupyter notebook following [this guide](../appendices/setup_vscode.qmd). You can copy fragments of the code, but make sure each code block is a different cell in you notebook. Also remember that you can add **Markdown** cells in between code cells, which are really useful to document your code.

The data we will use here is a `csv` file containing selected eruptions of the past 50 years. The first 5 rows of the data are illustrated in @tbl-first-5.


| Name            | Country     | Date                |   VEI |   Latitude |   Longitude |
|:----------------|:------------|:--------------------|------:|-----------:|------------:|
| St. Helens      | USA         | 1980-05-18 00:00:00 |     5 |    46.1914 |   -122.196  |
| Pinatubo        | Philippines | 1991-04-02 00:00:00 |     6 |    15.1501 |    120.347  |
| El Chichón      | Mexico      | 1982-03-28 00:00:00 |     5 |    17.3559 |    -93.2233 |
| Galunggung      | Indonesia   | 1982-04-05 00:00:00 |     4 |    -7.2567 |    108.077  |
| Nevado del Ruiz | Colombia    | 1985-11-13 00:00:00 |     3 |     4.895  |    -75.322  |

: First 5 rows of the dataset. {#tbl-first-5 .striped   }

::: {.callout-note collapse="true"}
## What is the VEI?

The Volcanic Explosivity Index - or VEI - is a scale to measure the magnitude of explosive eruptions based on the volume of tephra ejected during an eruption. It is a logarithmic scale in base 10:

| VEI | Min Volume (km³) | Max Volume (km³) | Approx. Frequency      |
|-----|------------------|------------------|------------------------|
| 0   | <0.00001         | 0.0001           | Daily                  |
| 1   | 0.0001           | 0.001            | Weekly                 |
| 2   | 0.001            | 0.01             | Yearly                 |
| 3   | 0.01             | 0.1              | Few per year           |
| 4   | 0.1              | 1                | ~10 per decade         |
| 5   | 1                | 10               | ~1 per decade          |
| 6   | 10               | 100              | ~1 per century         |
| 7   | 100              | 1000             | ~1 per several centuries|
| 8   | >1000            | -                | ~1 per 10,000 years    |

: VEI scale with minimum and maximum erupted volume and approximate frequency. {#tbl-vei .striped   }

:::

### Importing the library and the data {.unnumbered}

As always, we start by importing the `pandas` library as `pd`.

```{python}
#| label: load-packages
#| output-fold: true
#| output-summary: "Show output"

import pandas as pd
```

We load the dataset using the `pd.read_csv` function into a variable called `df` (for DataFrame) ([doc](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)). Remember that *functions* can take different *arguments*, which are extra keywords you can *pass* to make the behaviour of the function more specific to your need. Here, we pass one arguments to the `read_csv()` function: `parse_dates=['Date']` Specifies that the `Date` column should be treated as a date object.


<!-- ::: {.callout-tip}
## Function arguments

Remember that *functions* can take different *arguments*, which are extra keywords you can *pass* to make the behaviour of the function more specific to your need. Here, we one arguments to the `read_csv()` function:

- `index_col=0`: Specify that the index of the file is the first column. More on that soon if this is unclear.
- `parse_dates=['Date']`: Specify that the `Date` column should be treated as a date object.
::: -->


```{python}
#| lst-label: lst-load-data
#| lst-cap: Loading data from a csv file

df = pd.read_csv('data/dummy_volcanoes.csv', parse_dates=['Date']) # Load data
df.head() # Show the first 5 rows
```


#### Setting up the index {.unnumbered}

The output of @lst-load-data shows the first 5 rows in our DataFrame. As displayed in @fig-index, the first column is the *index* - which is currently just integer numbers. That can be acceptable in some cases, but for the sake of the exercise we will choose one column to become the index - here `Name`. 

@lst-set-index Illustrates the use of two useful functions:

- `.set_index()`: Uses a column as the DataFrame's index
- `.reset_index()`: Removes the column's index back to a sequential numbering as in @lst-load-data.

```{python}
#| lst-label: lst-set-index
#| lst-cap: Common functions to set the index of a DataFrame

df = df.set_index('VEI') # Set the 'VEI' column as an index
df = df.reset_index() # Shoots, I meant to set the 'Name' columns as an index
df = df.set_index('Name') # Here we go.
df.head()
```


#### Basic data exploration {.unnumbered}

Let's now explore the structure of the dataset with the following functions:

| Function         | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
|------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `df.head()`      | Prints the *first* 5 rows of the DataFrame ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html))                                                                                                                                                                                                                                                                                                                          |
| `df.tail()`      | Prints the *last* 5 rows of the DataFrame ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html))                                                                                                                                                                                                                                                                                                                           |
| `df.info()`      | Displays some info about the DataFrame, including the number of rows (*entries*) and columns ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)). Note the `Dtype` column: this is the type variable stored in each column including *strings* (`object`), *integer* (`int64`) and *float* (`int64`) numbers. See that the `Date` column is indeed stored as a `datetime` variable as requested above. |
| `df.shape`       | Returns a list containing the number of rows and columns of the DataFrame.                                                                                                                                                                                                                                                                                                                                                                           |
| `df.index`       | Returns a list containing the index along the *rows* of the DataFrame.                                                                                                                                                                                                                                                                                                                                                                           |
| `df.columns`     | Returns a list containing the index along the *columns* of the DataFrame.                                                                                                                                                                                                                                                                                                                                                                           |

::: {.callout-tip}

## Your turn!

Try these functions on `df` and get familiar with the output.

:::


### Querying data {.unnumbered}

Let's now review how we can access data contained in the DataFrame. This process, known as *indexing*, consists in specifying a row or a column (or ranges of rows and columns) where the data is stored. In `pandas`, there are two different ways to do that:

- By `label`: data is queried using the actual index/column name (e.g., the `VEI` column in the DataFrame above)
- By `location`: data is queried using the column location (e.g., the 3rd row)

#### Label-based indexing {.unnumbered}

![Label-based queries using `.loc`.](img/pandas_loc.png){#fig-pandas-loc}

##### Querying rows {.unnumbered}

When we know the exact label of the row or the column, we can use the `.loc` function to query the DataFrame (@fig-pandas-loc). Let's start by querying specific **rows**. @lst-set-index has defined the `Name` column as the *index* (i.e., row label), which means that we can simply pass the name of the volcano.

```{python}
# Get the row for "Calbuco" volcano
df.loc['Calbuco']

```

Note that the result is a *Series* (i.e., a 1-dimensional DataFrame where the columns become the index), not a DataFrame. If we want to **keep it as a DataFrame**, we can use double brackets. Double brackets can also be used to query **multiple rows**.

```{python}
df.loc[['Calbuco']] # Query one row and return it as a DataFrame
df.loc[['Calbuco', 'Taal']] # Query multiple rows
```

::: {.callout-note}
## Question

What is the VEI recorded for Etna volcano?

```{python}
#| echo: false
mcq({
    '1' : 0,
    '2' : 0,
    '3' : 0,
    '4' : 1,
    '5' : 0
})
```

What is the eruption date for Taal volcano?

```{python}
#| echo: false
mcq({
    '1980-05-18	' : 0,
    '1991-04-02' : 0,
    '2020-01-12' : 1,
    '1997-06-25' : 0,
    '2023-02-13' : 0
})
```

:::


::: {.callout-tip}
## Double brackets
In general, double brackets ``[[ ]]`` will return a DataFrame and not a Series. We will dominantly use this in the following examples.
:::


##### Querying columns {.unnumbered}

Let's now query specific **columns**. For example, querying the `VEI` column can be achieved in different ways. The simplest is to use the column name directly. We can also query **multiple columns** using double brackets


```{python}
df[['VEI']] # Get the VEI column
df[['Country', 'VEI']] # Query multiple columns
```


Note that until now, we have only retrieved either rows or columns (@fig-pandas-loc). We can also retrieve specific values by specifying **both the row and the column**.

```{python}
df.loc[['Calbuco', 'Taal']][['Country', 'VEI']]
```

#### Position-based indexing {.unnumbered}

![Position-based queries using `.iloc`.](img/pandas_iloc.png){#fig-pandas-iloc}


Some situations require querying data by *location* instead of *label* - let's say for instance we need to retrieve rows 10-20. This is done using the `.iloc` function (instead of the `.loc` function previously used; @fig-pandas-iloc). Remember that Python uses zero-based indexing (@cau-indexing), meaning that the first element is at position 0, the second at position 1, and so on.

The next example queries the first row - using again double brackets to return a **DataFrame**.

```{python}
df.iloc[[0]]
```

##### Get ranges of rows {.unnumbered}

We can get **a range of rows** using what is called *slicing*. This is done using the colon (`:`) operator. The next example queries rows 3 to 6 of the DataFrame. Note that the end index is exclusive, meaning that the element at the end index is not included in the result.

```{python}
df.iloc[2:6]
```

To get rows 3 to 6 and columns 2-3:

```{python}
df.iloc[0:5, 1:3]
```

##### Count rows from the last {.unnumbered}

To get the last 5 rows of the DataFrame:

```{python}
df.iloc[-5:]
```

##### Combining position-based and label-based queries {.unnumbered}

By experience, position-based queries is more used on *rows* than *columns*. For instance, we might want to access the first 10 rows because we don't know their associated labels, yet it is less likely that we ignore their *attributes*.
It is possible mix label-based and position-based indexing. For example, to get the first 5 rows and the `Country` and `VEI` columns:


```{python}
df.iloc[0:5][['Country', 'VEI']]
```





### Filtering data {.unnumbered}

#### Comparison operators {.unnumbered}

Now that we have reviewed how to access data, let's now see how to **filter** data using **boolean indexing**. For this, we need to review what are **comparison operators** (@tbl-comparison-operators). Let's assume the following variables:


```{python}
#| lst-label: lst-basic-bool
#| lst-cap: Variables used for illustrating logical operations
#| 
a = 1
b = 2
```

Applying the comparison operators in @tbl-comparison-operators will produce a variable of type `bool` - which can take only two values: `True` or `False`.

| Operator | Meaning                | Example      | Result      |
|----------|------------------------|--------------|-------------|
| `==`     | Equal to               | `a == b`     | `False`     |
| `!=`     | Not equal to           | `a != b`     | `True`      |
| `>`      | Greater than           | `a > b`      | `False`     |
| `<`      | Less than              | `a < b`      | `True`      |
| `>=`     | Greater than or equal  | `a >= b`     | `False`     |
| `<=`     | Less than or equal     | `a <= b`     | `True`      |

: Comparison operators in Python. {#tbl-comparison-operators .striped   }

We can apply comparison operators to DataFrame. Let's say we want to test what rows have a VEI of 4:

```{python}
#| lst-label: lst-bool
#| lst-cap: Create a boolean mask
df['VEI'] == 4
```

We can see that Galunggung, Taal, La Soufrière, Calbuco and Eyjafjallajökull return `True` to this condition. This is great, but what if we want to return the actual rows? We can use @lst-bool as a **mask** to then query the rows using `.loc`.

```{python}
#| lst-label: lst-bool-query
#| lst-cap: Query data using a boolean mask

mask = df['VEI'] == 4 # Create a mask
df.loc[mask] # Query the data

# Or, as a one line alternative:
df.loc[df['VEI'] == 4]
```

::: {.callout-note}
## Question

What volcanoes have a VEI of 5?

```{python}
#| echo: false
mcq({
    'La Soufrière and Calbuco' : 0,
    'Merapi and Agung' : 0,
    'Nyiragongo and Taal' : 0,
    'St. Helens and El Chichón' : 1
})
```

How many volcanoes are in the southern hemisphere? (hint: use the `df.shape` function to count them).

```{python}
#| echo: false
mcq({
    '1': 0,
    '2': 0,
    '4': 0,
    '6': 1,
    '12': 0
})
```

:::


##### String comparisons {.unnumbered}

We can also use comparison operators on columns containing **strings** (see @cau-dtypes for caveats). @lst-str-comp illustrates a basic string comparison using the `=` operator. @tbl-comparison-str shows additional operators for strings.

```{python}
#| lst-label: lst-str-comp
#| lst-cap: Basic comparison operation on strings


df.loc[df['Country'] == 'Indonesia']
```

| Operation         | Example                                 | Description                                         |
|-------------------|-----------------------------------------|-----------------------------------------------------|
| contains          | `df['Name'].str.contains('Soufrière')`  | Checks if each string contains a substring          |
| startswith        | `df['Name'].str.startswith('E')`        | Checks if each string starts with a substring       |
| endswith          | `df['Name'].str.endswith('o')`          | Checks if each string ends with a substring         |


: Common string comparison operations. {#tbl-comparison-str .striped   }


::: {#cau-dtypes .callout-caution collapse="true"}
## Compare what is comparable!

When using the comparison operators in @tbl-comparison-operators, we need to make sure that we are comparing data that have the **same type**. In @lst-bool, we are comparing the column `VEI` with an integer number. You can check the data type of a DataFrame using `df.dtypes`. 

Not all comparison operators work with all data type. For instance, you can test if a column contains a specific string using the `==` or `!=` operators, but the other won't work as they are *illogical*.
:::

#### Logical operators {.unnumbered}

But what if we want to create more complex filters based on different rules? We can use **logical operators** to combine several comparison operators. Going back to the example in @lst-basic-bool, @tbl-logical-operators illustrates the use of logical operators.

| Operator | Meaning                 | Example                        | Result      |
|----------|-------------------------|--------------------------------|-------------|
| `&`      | Logical AND             | `(a > 1) & (b < 3)`            | `False`     |
| `|`      | Logical OR              | `(a == 1) | (b == 1)`           | `True`      |
| `~`      | Logical NOT             | `~(a == 1)`                    | `False`     |

: Logical operators in pandas for combining boolean conditions. Use parentheses around each condition. {#tbl-logical-operators .striped }

Let's gather all volcanoes that have a VEI of 3 and are in Indonesia:

```{python}
#| lst-label: lst-logical-query
#| lst-cap: Complex filtering using logical operators

mask = (df['VEI'] == 3) & (df['Country'] == 'Indonesia') # Create a mask - don't forget parentheses!
df.loc[mask] # Query the data

```

::: {.callout-note}
## Question

How many volcanoes are either in Chile **or** in the USA?

```{python}
#| echo: false
mcq({
    '1': 0,
    '3': 0,
    '5': 1,
    '8': 0
})
```

How many volcanoes are in the southern hemisphere **and** have a VEI≥4?

```{python}
#| echo: false
mcq({
    '1': 0,
    '2': 1,
    '8': 0,
    '12': 0
})
```

:::



### Rearranging data {.unnumbered}

#### Sorting data {.unnumbered}

The main function to sort data is `.sort_values` ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html)). It is necessary to review how *three arguments* can alter the function's behaviour:

1. `by`: First argument (required) is the label of index/row used to sort the data. It is possible to sort by multiple columns by passing a list of values.
2. `axis`: Specifies whether sorting rows (`axis = 0` - in which case `by` is a column name) or sorting columns (`axis = 1`, in which case `by` is an index value). The documentation specifies `axis = 0`, which means that rows will be sorted if `axis` is not specified.
3. `ascending`: Using a *bool* (remember, this is a True/False behaviour), specifies if values are sorted in *ascending* (`ascending = True`, default behaviour is not specified) or *descending* (`ascending = False`) order.


```{python}
#| lst-label: lst-sort
#| lst-cap: Basic sorting operations
#| eval: false

df.sort_values('VEI') # Sort volcanoes by VEI in ascending number
df.sort_values('Date', ascending=False) # Sort volcanoes by eruption dates from recent to old
df.sort_values('Country') # .sort_values also work on strings to sort alphabetically
df.sort_values(['Latitude', 'Longitude']) # Sorting using multiple columns
```


::: {.callout-note}
## Question

After sorting the data in **descending order** by VEI and time, what are the three first volcanoes?

```{python}
#| echo: false
mcq({
    'Nyiragongo, Ontake, Kīlauea': 0,
    'Kīlauea, Ontake, Nyiragongo': 0,
    'Pinatubo, El Chichon, St Helens': 1,
    'St Helens, El Chichon, Pinatubo': 0
})
```
:::



### Operations {.unnumbered}

Let's now see how we can manipulate and operate on data contained within our DataFrame. @tbl-op-arith and @tbl-op-str respectively illustrate arithmetic and string-based operators that can be applied on parts of the DataFrame.


#### Numeric operations {.unnumbered}

@lst-op1 Illustrates how to half the VEI column save the results to a new column.

```{python}
#| lst-label: lst-op1
#| lst-cap: Divide VEI by two and save the results to a new column.

df['VEI_halved'] = df['VEI'] / 2

```

::: {.callout-note}
## Exercise

Longitudes are expressed as degrees E (i.e., from 0–180 ) and degrees W (i.e., from -180–0). Use operators to convert longitudes to degrees E (i.e., from 0–360) and store the results to a column called `Longitude_E`. To do so:

1. Define a mask where Longitudes are negative using [logical operators]
2. Where the mask is `True` (i.e. where the longitude is negative), add the longitude (or subtract its absolute value) to 360


::: {.callout-tip collapse="true"}
## Define a mask
Start by defining a mask

::: {.callout-tip collapse="true"}
## How?

```python
mask = df['Longitude'] <= 0
```
:::

:::

::: {.callout-tip collapse="true"}
## Select the values
Select the values using `.loc` and do the maths.

::: {.callout-tip collapse="true"}
## How?

```python
360 + df.loc[mask, 'Longitude']
```
:::

:::

::: {.callout-tip collapse="true"}
## Store back the values

```python
df.loc[mask, 'Longitude_E'] = 360 + df.loc[mask, 'Longitude']
```
:::


:::

| Operation      | Symbol | Example                | Description                                 |
|----------------|--------|------------------------|---------------------------------------------|
| Addition       | `+`    | `df['VEI'] + 1`        | Adds a value to each element                |
| Subtraction    | `-`    | `df['VEI'] - 1`        | Subtracts a value from each element         |
| Multiplication | `*`    | `df['VEI'] * 2`        | Multiplies each element by a value          |
| Division       | `/`    | `df['VEI'] / 2`        | Divides each element by a value             |
| Exponentiation | `**`   | `df['VEI'] ** 2`       | Raises each element to a power              |
| Modulo         | `%`    | `df['VEI'] % 2`        | Remainder after division for each element   |

: Common arithmetic operations on numerical pandas columns. {#tbl-op-arith .striped   }



#### String operations {.unnumbered}



| Operation         | Example                                 | Description                                         |
|-------------------|-----------------------------------------|-----------------------------------------------------|
| Concatenation     | `df['Country'] + ' volcano'`            | Adds a string to each element                       |
| String length     | `df['Country'].str.len()`                  | Returns the length of each string                   |
| Uppercase         | `df['Country'].str.upper()`             | Converts each string to uppercase                   |
| Lowercase         | `df['Country'].str.lower()`             | Converts each string to lowercase                   |
| Replace           | `df['Country'].str.replace('USA', 'US')`| Replaces substrings in each string                  |

: Common string operations on pandas columns. {#tbl-op-str .striped   }