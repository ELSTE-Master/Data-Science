{"title":"Intro to Pandas","markdown":{"yaml":{"title":"Intro to Pandas","format":{"html":{"code-fold":false,"code-line-numbers":true,"css":["../assets/webex.css"],"include-after-body":["../assets/webex.js"],"embed-resources":true}},"jupyter":"python3"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n```{python}\n#| echo: false\nfrom pywebexercises.exercises import mcq, longmcq, torf\nimport matplotlib.pyplot as plt\nplt.rcParams.update({\n    \"figure.facecolor\":  (0.0, 0.0, 0.0, 0.0),  # red   with alpha = 30%\n})\n```\n\n\nWe will start our data science journey by learning a bit about the most useful Python library for this class: **Pandas**. As a reminder, a *library* is a set of tools we load on top of Python that provides new functionalities for a specific problem or type of analysis. Here, Pandas provides functions for **data manipulation and analysis**, handling structured data like tables or time series and facilitating numerous tasks you might encounter as a scientist. These include:\n\n- **Reading/writing data** from various commonly-used formats (CSV, Excel, SQL, JSON, etc.)\n- Handling **missing data**\n- **Filtering**, **sorting**, **reshaping** and **grouping** data\n- **Aggregating** data (sum, mean, count, etc.)\n- **Time series support** (date ranges, frequency conversions)\n- **Statistical operations**\n\n### Today's objectives {.unnumbered}\n\nThe objective of this class is by no way to make you an expert in Pandas and data science. Rather, the objective is to take you through the most basic manipulations in order to build the confidence to keep on exploring the use of scientific coding and to include it into your research pipeline. The objectives of this module are to review:\n\n- [x] What is a Pandas DataFrame and its basic anatomy\n- [x] How to *load data* in a DataFrame\n- [x] How to *access* data (e.g., query by label/position)\n- [x] How to *filter* data (e.g., comparison and logical operators)\n- [x] How to *rearrange* data (e.g., sorting values)\n- [x] How to *operate* on data (e.g., arithmetic and string operations)\n\nWe first start by reviewing the [data structure](#pandas-data-structure) behind Pandas, then we will move on to a [coding exercise](#coding-playground) to make you familiar with some basic functionalities.\n\n## Pandas data structure\n\nPandas consists of two main types of **data structures**. Let's make an analogy with Excel.\n\n1. **Series**: A 1D labeled array. Think of a 2-columns Excel spreadsheet where the left column would contain a *label* (e.g., the time of a measurement) and the right column would contain a *value* (e.g., the actual value measured at the time specified in the label, let's say the temperature of a river).\n2. **DataFrame**: A 2D labeled table. This is the same as an Excel spreadsheet that would contain more columns than a Series. You can think of having measurements of different variables contained in each column (e.g., the flow rate, the turbidity etc...).\n\nThe keyword here is **labelled**. In Excel, you might get a column using *letters* and rows using *numbers*. In Pandas, you can use the column name (e.g., `water_temperature`) or the row label (e.g., `2021-06-15 14:19:14`).\n\n\n::: {.callout-note}\n## DataFrame\nThroughout this class we will focus on the use of **DataFrames**, not Series. Keep in mind that the behaviour between both is almost identical.\n:::\n\n### Anatomy of a DataFrame {.unnumbered}\n\n@fig-anatomy shows the basic anatomy of a DataFrame that contains four **rows** and four **columns**). We already see some data structuring emerging:\n\n- *Rows* tend to represent **entries**, which can be:\n  - Different measurements at specific time steps\n  - Different samples collected at different place/times\n  - etc.\n- In contrast, *column* represent **attributes** and store the properties of each entry:\n  - The actual values of different measured parameters\n  - The location and time of collected samples, along with associated analyses (e.g., geochemistry)\n  - etc.\n\n\n\n![Basic anaotmy of a Pandas DataFrame.](img/pandas-1.png){#fig-anatomy}\n\nThe first row - i.e. the row containing the column *labels* - is not considered as an entry. This is because the **top row** of a dataframe is usually used as the *label* for the **columns**. Similarly, we might want to set the **first column** as a *label* for the **rows** (@fig-index). In a nutshell:\n\n- **Index** refers to the label of the **rows**. In the *index*, **values are usually unique** - meaning that each entry has a different label.\n- **Column** refers to the label of - logically - the **columns**\n\n![Index and columns of a DataFrame.](img/pandas-2.png){#fig-index}\n\n::: {#cau-indexing .callout-caution}\n## Indexing in Python\nRemember that in Python, indexing starts from 0 - so the first row or column has an index of 0.\n:::\n\n\n\n\n## Coding playground\n\nLet's get our hands dirty and start coding. Create a new Jupyter notebook following [this guide](../appendices/setup_vscode.qmd). You can copy fragments of the code, but make sure each code block is a different cell in you notebook. Also remember that you can add **Markdown** cells in between code cells, which are really useful to document your code.\n\nThe data we will use here is a `csv` file containing selected eruptions of the past 50 years. The first 5 rows of the data are illustrated in @tbl-first-5.\n\n\n| Name            | Country     | Date                |   VEI |   Latitude |   Longitude |\n|:----------------|:------------|:--------------------|------:|-----------:|------------:|\n| St. Helens      | USA         | 1980-05-18 00:00:00 |     5 |    46.1914 |   -122.196  |\n| Pinatubo        | Philippines | 1991-04-02 00:00:00 |     6 |    15.1501 |    120.347  |\n| El Chichón      | Mexico      | 1982-03-28 00:00:00 |     5 |    17.3559 |    -93.2233 |\n| Galunggung      | Indonesia   | 1982-04-05 00:00:00 |     4 |    -7.2567 |    108.077  |\n| Nevado del Ruiz | Colombia    | 1985-11-13 00:00:00 |     3 |     4.895  |    -75.322  |\n\n: First 5 rows of the dataset. {#tbl-first-5 .striped   }\n\n::: {.callout-note collapse=\"true\"}\n## What is the VEI?\n\nThe Volcanic Explosivity Index - or VEI - is a scale to measure the magnitude of explosive eruptions based on the volume of tephra ejected during an eruption. It is a logarithmic scale in base 10:\n\n| VEI | Min Volume (km³) | Max Volume (km³) | Approx. Frequency      |\n|-----|------------------|------------------|------------------------|\n| 0   | <0.00001         | 0.0001           | Daily                  |\n| 1   | 0.0001           | 0.001            | Weekly                 |\n| 2   | 0.001            | 0.01             | Yearly                 |\n| 3   | 0.01             | 0.1              | Few per year           |\n| 4   | 0.1              | 1                | ~10 per decade         |\n| 5   | 1                | 10               | ~1 per decade          |\n| 6   | 10               | 100              | ~1 per century         |\n| 7   | 100              | 1000             | ~1 per several centuries|\n| 8   | >1000            | -                | ~1 per 10,000 years    |\n\n: VEI scale with minimum and maximum erupted volume and approximate frequency. {#tbl-vei .striped   }\n\n:::\n\n### Importing the library and the data {.unnumbered}\n\nAs always, we start by importing the `pandas` library as `pd`.\n\n```{python}\n#| label: load-packages\n#| output-fold: true\n#| output-summary: \"Show output\"\n\nimport pandas as pd\n```\n\nWe load the dataset using the `pd.read_csv` function into a variable called `df` (for DataFrame) ([doc](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)). Remember that *functions* can take different *arguments*, which are extra keywords you can *pass* to make the behaviour of the function more specific to your need. Here, we pass one arguments to the `read_csv()` function: `parse_dates=['Date']` Specifies that the `Date` column should be treated as a date object.\n\n\n<!-- ::: {.callout-tip}\n## Function arguments\n\nRemember that *functions* can take different *arguments*, which are extra keywords you can *pass* to make the behaviour of the function more specific to your need. Here, we one arguments to the `read_csv()` function:\n\n- `index_col=0`: Specify that the index of the file is the first column. More on that soon if this is unclear.\n- `parse_dates=['Date']`: Specify that the `Date` column should be treated as a date object.\n::: -->\n\n\n```{python}\n#| lst-label: lst-load-data\n#| lst-cap: Loading data from a csv file\n\ndf = pd.read_csv('data/dummy_volcanoes.csv', parse_dates=['Date']) # Load data\ndf.head() # Show the first 5 rows\n```\n\n\n#### Setting up the index {.unnumbered}\n\nThe output of @lst-load-data shows the first 5 rows in our DataFrame. As displayed in @fig-index, the first column is the *index* - which is currently just integer numbers. That can be acceptable in some cases, but for the sake of the exercise we will choose one column to become the index - here `Name`. \n\n@lst-set-index Illustrates the use of two useful functions:\n\n- `.set_index()`: Uses a column as the DataFrame's index\n- `.reset_index()`: Removes the column's index back to a sequential numbering as in @lst-load-data.\n\n```{python}\n#| lst-label: lst-set-index\n#| lst-cap: Common functions to set the index of a DataFrame\n\ndf = df.set_index('VEI') # Set the 'VEI' column as an index\ndf = df.reset_index() # Shoots, I meant to set the 'Name' columns as an index\ndf = df.set_index('Name') # Here we go.\ndf.head()\n```\n\n\n#### Basic data exploration {.unnumbered}\n\nLet's now explore the structure of the dataset with the following functions:\n\n| Function         | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n|------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `df.head()`      | Prints the *first* 5 rows of the DataFrame ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html))                                                                                                                                                                                                                                                                                                                          |\n| `df.tail()`      | Prints the *last* 5 rows of the DataFrame ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html))                                                                                                                                                                                                                                                                                                                           |\n| `df.info()`      | Displays some info about the DataFrame, including the number of rows (*entries*) and columns ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)). Note the `Dtype` column: this is the type variable stored in each column including *strings* (`object`), *integer* (`int64`) and *float* (`int64`) numbers. See that the `Date` column is indeed stored as a `datetime` variable as requested above. |\n| `df.shape`       | Returns a list containing the number of rows and columns of the DataFrame.                                                                                                                                                                                                                                                                                                                                                                           |\n| `df.index`       | Returns a list containing the index along the *rows* of the DataFrame.                                                                                                                                                                                                                                                                                                                                                                           |\n| `df.columns`     | Returns a list containing the index along the *columns* of the DataFrame.                                                                                                                                                                                                                                                                                                                                                                           |\n\n::: {.callout-tip}\n\n## Your turn!\n\nTry these functions on `df` and get familiar with the output.\n\n:::\n\n\n### Querying data {.unnumbered}\n\nLet's now review how we can access data contained in the DataFrame. This process, known as *indexing*, consists in specifying a row or a column (or ranges of rows and columns) where the data is stored. In `pandas`, there are two different ways to do that:\n\n- By `label`: data is queried using the actual index/column name (e.g., the `VEI` column in the DataFrame above)\n- By `location`: data is queried using the column location (e.g., the 3rd row)\n\n#### Label-based indexing {.unnumbered}\n\n![Label-based queries using `.loc`.](img/pandas_loc.png){#fig-pandas-loc}\n\n##### Querying rows {.unnumbered}\n\nWhen we know the exact label of the row or the column, we can use the `.loc` function to query the DataFrame (@fig-pandas-loc). Let's start by querying specific **rows**. @lst-set-index has defined the `Name` column as the *index* (i.e., row label), which means that we can simply pass the name of the volcano.\n\n```{python}\n# Get the row for \"Calbuco\" volcano\ndf.loc['Calbuco']\n\n```\n\nNote that the result is a *Series* (i.e., a 1-dimensional DataFrame where the columns become the index), not a DataFrame. If we want to **keep it as a DataFrame**, we can use double brackets. Double brackets can also be used to query **multiple rows**.\n\n```{python}\ndf.loc[['Calbuco']] # Query one row and return it as a DataFrame\ndf.loc[['Calbuco', 'Taal']] # Query multiple rows\n```\n\n::: {.callout-note}\n## Question\n\nWhat is the VEI recorded for Etna volcano?\n\n```{python}\n#| echo: false\nmcq({\n    '1' : 0,\n    '2' : 0,\n    '3' : 0,\n    '4' : 1,\n    '5' : 0\n})\n```\n\nWhat is the eruption date for Taal volcano?\n\n```{python}\n#| echo: false\nmcq({\n    '1980-05-18\t' : 0,\n    '1991-04-02' : 0,\n    '2020-01-12' : 1,\n    '1997-06-25' : 0,\n    '2023-02-13' : 0\n})\n```\n\n:::\n\n\n::: {.callout-tip}\n## Double brackets\nIn general, double brackets ``[[ ]]`` will return a DataFrame and not a Series. We will dominantly use this in the following examples.\n:::\n\n\n##### Querying columns {.unnumbered}\n\nLet's now query specific **columns**. For example, querying the `VEI` column can be achieved in different ways. The simplest is to use the column name directly. We can also query **multiple columns** using double brackets\n\n\n```{python}\ndf[['VEI']] # Get the VEI column\ndf[['Country', 'VEI']] # Query multiple columns\n```\n\n\nNote that until now, we have only retrieved either rows or columns (@fig-pandas-loc). We can also retrieve specific values by specifying **both the row and the column**.\n\n```{python}\ndf.loc[['Calbuco', 'Taal']][['Country', 'VEI']]\n```\n\n#### Position-based indexing {.unnumbered}\n\n![Position-based queries using `.iloc`.](img/pandas_iloc.png){#fig-pandas-iloc}\n\n\nSome situations require querying data by *location* instead of *label* - let's say for instance we need to retrieve rows 10-20. This is done using the `.iloc` function (instead of the `.loc` function previously used; @fig-pandas-iloc). Remember that Python uses zero-based indexing (@cau-indexing), meaning that the first element is at position 0, the second at position 1, and so on.\n\nThe next example queries the first row - using again double brackets to return a **DataFrame**.\n\n```{python}\ndf.iloc[[0]]\n```\n\n##### Get ranges of rows {.unnumbered}\n\nWe can get **a range of rows** using what is called *slicing*. This is done using the colon (`:`) operator. The next example queries rows 3 to 6 of the DataFrame. Note that the end index is exclusive, meaning that the element at the end index is not included in the result.\n\n```{python}\ndf.iloc[2:6]\n```\n\nTo get rows 3 to 6 and columns 2-3:\n\n```{python}\ndf.iloc[0:5, 1:3]\n```\n\n##### Count rows from the last {.unnumbered}\n\nTo get the last 5 rows of the DataFrame:\n\n```{python}\ndf.iloc[-5:]\n```\n\n##### Combining position-based and label-based queries {.unnumbered}\n\nBy experience, position-based queries is more used on *rows* than *columns*. For instance, we might want to access the first 10 rows because we don't know their associated labels, yet it is less likely that we ignore their *attributes*.\nIt is possible mix label-based and position-based indexing. For example, to get the first 5 rows and the `Country` and `VEI` columns:\n\n\n```{python}\ndf.iloc[0:5][['Country', 'VEI']]\n```\n\n\n\n\n\n### Filtering data {.unnumbered}\n\n#### Comparison operators {.unnumbered}\n\nNow that we have reviewed how to access data, let's now see how to **filter** data using **boolean indexing**. For this, we need to review what are **comparison operators** (@tbl-comparison-operators). Let's assume the following variables:\n\n\n```{python}\n#| lst-label: lst-basic-bool\n#| lst-cap: Variables used for illustrating logical operations\n#| \na = 1\nb = 2\n```\n\nApplying the comparison operators in @tbl-comparison-operators will produce a variable of type `bool` - which can take only two values: `True` or `False`.\n\n| Operator | Meaning                | Example      | Result      |\n|----------|------------------------|--------------|-------------|\n| `==`     | Equal to               | `a == b`     | `False`     |\n| `!=`     | Not equal to           | `a != b`     | `True`      |\n| `>`      | Greater than           | `a > b`      | `False`     |\n| `<`      | Less than              | `a < b`      | `True`      |\n| `>=`     | Greater than or equal  | `a >= b`     | `False`     |\n| `<=`     | Less than or equal     | `a <= b`     | `True`      |\n\n: Comparison operators in Python. {#tbl-comparison-operators .striped   }\n\nWe can apply comparison operators to DataFrame. Let's say we want to test what rows have a VEI of 4:\n\n```{python}\n#| lst-label: lst-bool\n#| lst-cap: Create a boolean mask\ndf['VEI'] == 4\n```\n\nWe can see that Galunggung, Taal, La Soufrière, Calbuco and Eyjafjallajökull return `True` to this condition. This is great, but what if we want to return the actual rows? We can use @lst-bool as a **mask** to then query the rows using `.loc`.\n\n```{python}\n#| lst-label: lst-bool-query\n#| lst-cap: Query data using a boolean mask\n\nmask = df['VEI'] == 4 # Create a mask\ndf.loc[mask] # Query the data\n\n# Or, as a one line alternative:\ndf.loc[df['VEI'] == 4]\n```\n\n::: {.callout-note}\n## Question\n\nWhat volcanoes have a VEI of 5?\n\n```{python}\n#| echo: false\nmcq({\n    'La Soufrière and Calbuco' : 0,\n    'Merapi and Agung' : 0,\n    'Nyiragongo and Taal' : 0,\n    'St. Helens and El Chichón' : 1\n})\n```\n\nHow many volcanoes are in the southern hemisphere? (hint: use the `df.shape` function to count them).\n\n```{python}\n#| echo: false\nmcq({\n    '1': 0,\n    '2': 0,\n    '4': 0,\n    '6': 1,\n    '12': 0\n})\n```\n\n:::\n\n\n##### String comparisons {.unnumbered}\n\nWe can also use comparison operators on columns containing **strings** (see @cau-dtypes for caveats). @lst-str-comp illustrates a basic string comparison using the `=` operator. @tbl-comparison-str shows additional operators for strings.\n\n```{python}\n#| lst-label: lst-str-comp\n#| lst-cap: Basic comparison operation on strings\n\n\ndf.loc[df['Country'] == 'Indonesia']\n```\n\n| Operation         | Example                                 | Description                                         |\n|-------------------|-----------------------------------------|-----------------------------------------------------|\n| Contains          | `df['Name'].str.contains('Soufrière')`  | Checks if each string contains a substring          |\n| Startswith        | `df['Name'].str.startswith('E')`        | Checks if each string starts with a substring       |\n| Endswith          | `df['Name'].str.endswith('o')`          | Checks if each string ends with a substring         |\n\n\n: Common string comparison operations. {#tbl-comparison-str .striped   }\n\n\n::: {#cau-dtypes .callout-caution collapse=\"true\"}\n## Compare what is comparable!\n\nWhen using the comparison operators in @tbl-comparison-operators, we need to make sure that we are comparing data that have the **same type**. In @lst-bool, we are comparing the column `VEI` with an integer number. You can check the data type of a DataFrame using `df.dtypes`. \n\nNot all comparison operators work with all data type. For instance, you can test if a column contains a specific string using the `==` or `!=` operators, but the other won't work as they are *illogical*.\n:::\n\n#### Logical operators {.unnumbered}\n\nBut what if we want to create more complex filters based on different rules? We can use **logical operators** to combine several comparison operators. Going back to the example in @lst-basic-bool, @tbl-logical-operators illustrates the use of logical operators.\n\n| Operator | Meaning                 | Example                        | Result      |\n|----------|-------------------------|--------------------------------|-------------|\n| `&`      | Logical AND             | `(a > 1) & (b < 3)`            | `False`     |\n| `|`      | Logical OR              | `(a == 1) | (b == 1)`           | `True`      |\n| `~`      | Logical NOT             | `~(a == 1)`                    | `False`     |\n\n: Logical operators in pandas for combining boolean conditions. Use parentheses around each condition. {#tbl-logical-operators .striped }\n\nLet's gather all volcanoes that have a VEI of 3 and are in Indonesia:\n\n```{python}\n#| lst-label: lst-logical-query\n#| lst-cap: Complex filtering using logical operators\n\nmask = (df['VEI'] == 3) & (df['Country'] == 'Indonesia') # Create a mask - don't forget parentheses!\ndf.loc[mask] # Query the data\n\n```\n\n::: {.callout-note}\n## Question\n\nHow many volcanoes are either in Chile **or** in the USA?\n\n```{python}\n#| echo: false\nmcq({\n    '1': 0,\n    '3': 0,\n    '5': 1,\n    '8': 0\n})\n```\n\nHow many volcanoes are in the southern hemisphere **and** have a VEI≥4?\n\n```{python}\n#| echo: false\nmcq({\n    '1': 0,\n    '2': 1,\n    '8': 0,\n    '12': 0\n})\n```\n\n:::\n\n\n\n### Rearranging data {.unnumbered}\n\n#### Sorting data {.unnumbered}\n\nThe main function to sort data is `.sort_values` ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html)). It is necessary to review how *three arguments* can alter the function's behaviour:\n\n1. `by`: First argument (required) is the label of index/row used to sort the data. It is possible to sort by multiple columns by passing a list of values.\n2. `axis`: Specifies whether sorting rows (`axis = 0` - in which case `by` is a column name) or sorting columns (`axis = 1`, in which case `by` is an index value). The documentation specifies `axis = 0`, which means that rows will be sorted if `axis` is not specified.\n3. `ascending`: Using a *bool* (remember, this is a True/False behaviour), specifies if values are sorted in *ascending* (`ascending = True`, default behaviour is not specified) or *descending* (`ascending = False`) order.\n\n\n```{python}\n#| lst-label: lst-sort\n#| lst-cap: Basic sorting operations\n#| eval: false\n\ndf.sort_values('VEI') # Sort volcanoes by VEI in ascending number\ndf.sort_values('Date', ascending=False) # Sort volcanoes by eruption dates from recent to old\ndf.sort_values('Country') # .sort_values also work on strings to sort alphabetically\ndf.sort_values(['Latitude', 'Longitude']) # Sorting using multiple columns\n```\n\n\n::: {.callout-note}\n## Question\n\nAfter sorting the data in **descending order** by VEI and time, what are the three first volcanoes?\n\n```{python}\n#| echo: false\nmcq({\n    'Nyiragongo, Ontake, Kīlauea': 0,\n    'Kīlauea, Ontake, Nyiragongo': 0,\n    'Pinatubo, El Chichon, St Helens': 1,\n    'St Helens, El Chichon, Pinatubo': 0\n})\n```\n:::\n\n\n\n### Operations {.unnumbered}\n\nLet's now see how we can manipulate and operate on data contained within our DataFrame. @tbl-op-arith and @tbl-op-str respectively illustrate arithmetic and string-based operators that can be applied on parts of the DataFrame.\n\n\n#### Numeric operations {.unnumbered}\n\n@lst-op1 Illustrates how to half the VEI column save the results to a new column.\n\n```{python}\n#| lst-label: lst-op1\n#| lst-cap: Divide VEI by two and save the results to a new column.\n\ndf['VEI_halved'] = df['VEI'] / 2\n\n```\n\n::: {.callout-note}\n## Exercise\n\nLongitudes are expressed as degrees E (i.e., from 0–180 ) and degrees W (i.e., from -180–0). Use operators to convert longitudes to degrees E (i.e., from 0–360) and store the results to a column called `Longitude_E`. To do so:\n\n1. Define a mask where Longitudes are negative using [logical operators]\n2. Where the mask is `True` (i.e. where the longitude is negative), add the longitude (or subtract its absolute value) to 360\n\n\n::: {.callout-tip collapse=\"true\"}\n## Define a mask\nStart by defining a mask\n\n::: {.callout-tip collapse=\"true\"}\n## How?\n\n```python\nmask = df['Longitude'] <= 0\n```\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Select the values\nSelect the values using `.loc` and do the maths.\n\n::: {.callout-tip collapse=\"true\"}\n## How?\n\n```python\n360 + df.loc[mask, 'Longitude']\n```\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Store back the values\n\n```python\ndf.loc[mask, 'Longitude_E'] = 360 + df.loc[mask, 'Longitude']\n```\n:::\n\n\n:::\n\n| Operation      | Symbol | Example                | Description                                 |\n|----------------|--------|------------------------|---------------------------------------------|\n| Addition       | `+`    | `df['VEI'] + 1`        | Adds a value to each element                |\n| Subtraction    | `-`    | `df['VEI'] - 1`        | Subtracts a value from each element         |\n| Multiplication | `*`    | `df['VEI'] * 2`        | Multiplies each element by a value          |\n| Division       | `/`    | `df['VEI'] / 2`        | Divides each element by a value             |\n| Exponentiation | `**`   | `df['VEI'] ** 2`       | Raises each element to a power              |\n| Modulo         | `%`    | `df['VEI'] % 2`        | Remainder after division for each element   |\n\n: Common arithmetic operations on numerical pandas columns. {#tbl-op-arith .striped   }\n\n\n\n#### String operations {.unnumbered}\n\n\n\n| Operation         | Example                                 | Description                                         |\n|-------------------|-----------------------------------------|-----------------------------------------------------|\n| Concatenation     | `df['Country'] + ' volcano'`            | Adds a string to each element                       |\n| String length     | `df['Country'].str.len()`                  | Returns the length of each string                   |\n| Uppercase         | `df['Country'].str.upper()`             | Converts each string to uppercase                   |\n| Lowercase         | `df['Country'].str.lower()`             | Converts each string to lowercase                   |\n| Replace           | `df['Country'].str.replace('USA', 'US')`| Replaces substrings in each string                  |\n\n: Common string operations on pandas columns. {#tbl-op-str .striped   }","srcMarkdownNoYaml":"\n\n```{python}\n#| echo: false\nfrom pywebexercises.exercises import mcq, longmcq, torf\nimport matplotlib.pyplot as plt\nplt.rcParams.update({\n    \"figure.facecolor\":  (0.0, 0.0, 0.0, 0.0),  # red   with alpha = 30%\n})\n```\n\n## Introduction\n\nWe will start our data science journey by learning a bit about the most useful Python library for this class: **Pandas**. As a reminder, a *library* is a set of tools we load on top of Python that provides new functionalities for a specific problem or type of analysis. Here, Pandas provides functions for **data manipulation and analysis**, handling structured data like tables or time series and facilitating numerous tasks you might encounter as a scientist. These include:\n\n- **Reading/writing data** from various commonly-used formats (CSV, Excel, SQL, JSON, etc.)\n- Handling **missing data**\n- **Filtering**, **sorting**, **reshaping** and **grouping** data\n- **Aggregating** data (sum, mean, count, etc.)\n- **Time series support** (date ranges, frequency conversions)\n- **Statistical operations**\n\n### Today's objectives {.unnumbered}\n\nThe objective of this class is by no way to make you an expert in Pandas and data science. Rather, the objective is to take you through the most basic manipulations in order to build the confidence to keep on exploring the use of scientific coding and to include it into your research pipeline. The objectives of this module are to review:\n\n- [x] What is a Pandas DataFrame and its basic anatomy\n- [x] How to *load data* in a DataFrame\n- [x] How to *access* data (e.g., query by label/position)\n- [x] How to *filter* data (e.g., comparison and logical operators)\n- [x] How to *rearrange* data (e.g., sorting values)\n- [x] How to *operate* on data (e.g., arithmetic and string operations)\n\nWe first start by reviewing the [data structure](#pandas-data-structure) behind Pandas, then we will move on to a [coding exercise](#coding-playground) to make you familiar with some basic functionalities.\n\n## Pandas data structure\n\nPandas consists of two main types of **data structures**. Let's make an analogy with Excel.\n\n1. **Series**: A 1D labeled array. Think of a 2-columns Excel spreadsheet where the left column would contain a *label* (e.g., the time of a measurement) and the right column would contain a *value* (e.g., the actual value measured at the time specified in the label, let's say the temperature of a river).\n2. **DataFrame**: A 2D labeled table. This is the same as an Excel spreadsheet that would contain more columns than a Series. You can think of having measurements of different variables contained in each column (e.g., the flow rate, the turbidity etc...).\n\nThe keyword here is **labelled**. In Excel, you might get a column using *letters* and rows using *numbers*. In Pandas, you can use the column name (e.g., `water_temperature`) or the row label (e.g., `2021-06-15 14:19:14`).\n\n\n::: {.callout-note}\n## DataFrame\nThroughout this class we will focus on the use of **DataFrames**, not Series. Keep in mind that the behaviour between both is almost identical.\n:::\n\n### Anatomy of a DataFrame {.unnumbered}\n\n@fig-anatomy shows the basic anatomy of a DataFrame that contains four **rows** and four **columns**). We already see some data structuring emerging:\n\n- *Rows* tend to represent **entries**, which can be:\n  - Different measurements at specific time steps\n  - Different samples collected at different place/times\n  - etc.\n- In contrast, *column* represent **attributes** and store the properties of each entry:\n  - The actual values of different measured parameters\n  - The location and time of collected samples, along with associated analyses (e.g., geochemistry)\n  - etc.\n\n\n\n![Basic anaotmy of a Pandas DataFrame.](img/pandas-1.png){#fig-anatomy}\n\nThe first row - i.e. the row containing the column *labels* - is not considered as an entry. This is because the **top row** of a dataframe is usually used as the *label* for the **columns**. Similarly, we might want to set the **first column** as a *label* for the **rows** (@fig-index). In a nutshell:\n\n- **Index** refers to the label of the **rows**. In the *index*, **values are usually unique** - meaning that each entry has a different label.\n- **Column** refers to the label of - logically - the **columns**\n\n![Index and columns of a DataFrame.](img/pandas-2.png){#fig-index}\n\n::: {#cau-indexing .callout-caution}\n## Indexing in Python\nRemember that in Python, indexing starts from 0 - so the first row or column has an index of 0.\n:::\n\n\n\n\n## Coding playground\n\nLet's get our hands dirty and start coding. Create a new Jupyter notebook following [this guide](../appendices/setup_vscode.qmd). You can copy fragments of the code, but make sure each code block is a different cell in you notebook. Also remember that you can add **Markdown** cells in between code cells, which are really useful to document your code.\n\nThe data we will use here is a `csv` file containing selected eruptions of the past 50 years. The first 5 rows of the data are illustrated in @tbl-first-5.\n\n\n| Name            | Country     | Date                |   VEI |   Latitude |   Longitude |\n|:----------------|:------------|:--------------------|------:|-----------:|------------:|\n| St. Helens      | USA         | 1980-05-18 00:00:00 |     5 |    46.1914 |   -122.196  |\n| Pinatubo        | Philippines | 1991-04-02 00:00:00 |     6 |    15.1501 |    120.347  |\n| El Chichón      | Mexico      | 1982-03-28 00:00:00 |     5 |    17.3559 |    -93.2233 |\n| Galunggung      | Indonesia   | 1982-04-05 00:00:00 |     4 |    -7.2567 |    108.077  |\n| Nevado del Ruiz | Colombia    | 1985-11-13 00:00:00 |     3 |     4.895  |    -75.322  |\n\n: First 5 rows of the dataset. {#tbl-first-5 .striped   }\n\n::: {.callout-note collapse=\"true\"}\n## What is the VEI?\n\nThe Volcanic Explosivity Index - or VEI - is a scale to measure the magnitude of explosive eruptions based on the volume of tephra ejected during an eruption. It is a logarithmic scale in base 10:\n\n| VEI | Min Volume (km³) | Max Volume (km³) | Approx. Frequency      |\n|-----|------------------|------------------|------------------------|\n| 0   | <0.00001         | 0.0001           | Daily                  |\n| 1   | 0.0001           | 0.001            | Weekly                 |\n| 2   | 0.001            | 0.01             | Yearly                 |\n| 3   | 0.01             | 0.1              | Few per year           |\n| 4   | 0.1              | 1                | ~10 per decade         |\n| 5   | 1                | 10               | ~1 per decade          |\n| 6   | 10               | 100              | ~1 per century         |\n| 7   | 100              | 1000             | ~1 per several centuries|\n| 8   | >1000            | -                | ~1 per 10,000 years    |\n\n: VEI scale with minimum and maximum erupted volume and approximate frequency. {#tbl-vei .striped   }\n\n:::\n\n### Importing the library and the data {.unnumbered}\n\nAs always, we start by importing the `pandas` library as `pd`.\n\n```{python}\n#| label: load-packages\n#| output-fold: true\n#| output-summary: \"Show output\"\n\nimport pandas as pd\n```\n\nWe load the dataset using the `pd.read_csv` function into a variable called `df` (for DataFrame) ([doc](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)). Remember that *functions* can take different *arguments*, which are extra keywords you can *pass* to make the behaviour of the function more specific to your need. Here, we pass one arguments to the `read_csv()` function: `parse_dates=['Date']` Specifies that the `Date` column should be treated as a date object.\n\n\n<!-- ::: {.callout-tip}\n## Function arguments\n\nRemember that *functions* can take different *arguments*, which are extra keywords you can *pass* to make the behaviour of the function more specific to your need. Here, we one arguments to the `read_csv()` function:\n\n- `index_col=0`: Specify that the index of the file is the first column. More on that soon if this is unclear.\n- `parse_dates=['Date']`: Specify that the `Date` column should be treated as a date object.\n::: -->\n\n\n```{python}\n#| lst-label: lst-load-data\n#| lst-cap: Loading data from a csv file\n\ndf = pd.read_csv('data/dummy_volcanoes.csv', parse_dates=['Date']) # Load data\ndf.head() # Show the first 5 rows\n```\n\n\n#### Setting up the index {.unnumbered}\n\nThe output of @lst-load-data shows the first 5 rows in our DataFrame. As displayed in @fig-index, the first column is the *index* - which is currently just integer numbers. That can be acceptable in some cases, but for the sake of the exercise we will choose one column to become the index - here `Name`. \n\n@lst-set-index Illustrates the use of two useful functions:\n\n- `.set_index()`: Uses a column as the DataFrame's index\n- `.reset_index()`: Removes the column's index back to a sequential numbering as in @lst-load-data.\n\n```{python}\n#| lst-label: lst-set-index\n#| lst-cap: Common functions to set the index of a DataFrame\n\ndf = df.set_index('VEI') # Set the 'VEI' column as an index\ndf = df.reset_index() # Shoots, I meant to set the 'Name' columns as an index\ndf = df.set_index('Name') # Here we go.\ndf.head()\n```\n\n\n#### Basic data exploration {.unnumbered}\n\nLet's now explore the structure of the dataset with the following functions:\n\n| Function         | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n|------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `df.head()`      | Prints the *first* 5 rows of the DataFrame ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html))                                                                                                                                                                                                                                                                                                                          |\n| `df.tail()`      | Prints the *last* 5 rows of the DataFrame ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html))                                                                                                                                                                                                                                                                                                                           |\n| `df.info()`      | Displays some info about the DataFrame, including the number of rows (*entries*) and columns ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)). Note the `Dtype` column: this is the type variable stored in each column including *strings* (`object`), *integer* (`int64`) and *float* (`int64`) numbers. See that the `Date` column is indeed stored as a `datetime` variable as requested above. |\n| `df.shape`       | Returns a list containing the number of rows and columns of the DataFrame.                                                                                                                                                                                                                                                                                                                                                                           |\n| `df.index`       | Returns a list containing the index along the *rows* of the DataFrame.                                                                                                                                                                                                                                                                                                                                                                           |\n| `df.columns`     | Returns a list containing the index along the *columns* of the DataFrame.                                                                                                                                                                                                                                                                                                                                                                           |\n\n::: {.callout-tip}\n\n## Your turn!\n\nTry these functions on `df` and get familiar with the output.\n\n:::\n\n\n### Querying data {.unnumbered}\n\nLet's now review how we can access data contained in the DataFrame. This process, known as *indexing*, consists in specifying a row or a column (or ranges of rows and columns) where the data is stored. In `pandas`, there are two different ways to do that:\n\n- By `label`: data is queried using the actual index/column name (e.g., the `VEI` column in the DataFrame above)\n- By `location`: data is queried using the column location (e.g., the 3rd row)\n\n#### Label-based indexing {.unnumbered}\n\n![Label-based queries using `.loc`.](img/pandas_loc.png){#fig-pandas-loc}\n\n##### Querying rows {.unnumbered}\n\nWhen we know the exact label of the row or the column, we can use the `.loc` function to query the DataFrame (@fig-pandas-loc). Let's start by querying specific **rows**. @lst-set-index has defined the `Name` column as the *index* (i.e., row label), which means that we can simply pass the name of the volcano.\n\n```{python}\n# Get the row for \"Calbuco\" volcano\ndf.loc['Calbuco']\n\n```\n\nNote that the result is a *Series* (i.e., a 1-dimensional DataFrame where the columns become the index), not a DataFrame. If we want to **keep it as a DataFrame**, we can use double brackets. Double brackets can also be used to query **multiple rows**.\n\n```{python}\ndf.loc[['Calbuco']] # Query one row and return it as a DataFrame\ndf.loc[['Calbuco', 'Taal']] # Query multiple rows\n```\n\n::: {.callout-note}\n## Question\n\nWhat is the VEI recorded for Etna volcano?\n\n```{python}\n#| echo: false\nmcq({\n    '1' : 0,\n    '2' : 0,\n    '3' : 0,\n    '4' : 1,\n    '5' : 0\n})\n```\n\nWhat is the eruption date for Taal volcano?\n\n```{python}\n#| echo: false\nmcq({\n    '1980-05-18\t' : 0,\n    '1991-04-02' : 0,\n    '2020-01-12' : 1,\n    '1997-06-25' : 0,\n    '2023-02-13' : 0\n})\n```\n\n:::\n\n\n::: {.callout-tip}\n## Double brackets\nIn general, double brackets ``[[ ]]`` will return a DataFrame and not a Series. We will dominantly use this in the following examples.\n:::\n\n\n##### Querying columns {.unnumbered}\n\nLet's now query specific **columns**. For example, querying the `VEI` column can be achieved in different ways. The simplest is to use the column name directly. We can also query **multiple columns** using double brackets\n\n\n```{python}\ndf[['VEI']] # Get the VEI column\ndf[['Country', 'VEI']] # Query multiple columns\n```\n\n\nNote that until now, we have only retrieved either rows or columns (@fig-pandas-loc). We can also retrieve specific values by specifying **both the row and the column**.\n\n```{python}\ndf.loc[['Calbuco', 'Taal']][['Country', 'VEI']]\n```\n\n#### Position-based indexing {.unnumbered}\n\n![Position-based queries using `.iloc`.](img/pandas_iloc.png){#fig-pandas-iloc}\n\n\nSome situations require querying data by *location* instead of *label* - let's say for instance we need to retrieve rows 10-20. This is done using the `.iloc` function (instead of the `.loc` function previously used; @fig-pandas-iloc). Remember that Python uses zero-based indexing (@cau-indexing), meaning that the first element is at position 0, the second at position 1, and so on.\n\nThe next example queries the first row - using again double brackets to return a **DataFrame**.\n\n```{python}\ndf.iloc[[0]]\n```\n\n##### Get ranges of rows {.unnumbered}\n\nWe can get **a range of rows** using what is called *slicing*. This is done using the colon (`:`) operator. The next example queries rows 3 to 6 of the DataFrame. Note that the end index is exclusive, meaning that the element at the end index is not included in the result.\n\n```{python}\ndf.iloc[2:6]\n```\n\nTo get rows 3 to 6 and columns 2-3:\n\n```{python}\ndf.iloc[0:5, 1:3]\n```\n\n##### Count rows from the last {.unnumbered}\n\nTo get the last 5 rows of the DataFrame:\n\n```{python}\ndf.iloc[-5:]\n```\n\n##### Combining position-based and label-based queries {.unnumbered}\n\nBy experience, position-based queries is more used on *rows* than *columns*. For instance, we might want to access the first 10 rows because we don't know their associated labels, yet it is less likely that we ignore their *attributes*.\nIt is possible mix label-based and position-based indexing. For example, to get the first 5 rows and the `Country` and `VEI` columns:\n\n\n```{python}\ndf.iloc[0:5][['Country', 'VEI']]\n```\n\n\n\n\n\n### Filtering data {.unnumbered}\n\n#### Comparison operators {.unnumbered}\n\nNow that we have reviewed how to access data, let's now see how to **filter** data using **boolean indexing**. For this, we need to review what are **comparison operators** (@tbl-comparison-operators). Let's assume the following variables:\n\n\n```{python}\n#| lst-label: lst-basic-bool\n#| lst-cap: Variables used for illustrating logical operations\n#| \na = 1\nb = 2\n```\n\nApplying the comparison operators in @tbl-comparison-operators will produce a variable of type `bool` - which can take only two values: `True` or `False`.\n\n| Operator | Meaning                | Example      | Result      |\n|----------|------------------------|--------------|-------------|\n| `==`     | Equal to               | `a == b`     | `False`     |\n| `!=`     | Not equal to           | `a != b`     | `True`      |\n| `>`      | Greater than           | `a > b`      | `False`     |\n| `<`      | Less than              | `a < b`      | `True`      |\n| `>=`     | Greater than or equal  | `a >= b`     | `False`     |\n| `<=`     | Less than or equal     | `a <= b`     | `True`      |\n\n: Comparison operators in Python. {#tbl-comparison-operators .striped   }\n\nWe can apply comparison operators to DataFrame. Let's say we want to test what rows have a VEI of 4:\n\n```{python}\n#| lst-label: lst-bool\n#| lst-cap: Create a boolean mask\ndf['VEI'] == 4\n```\n\nWe can see that Galunggung, Taal, La Soufrière, Calbuco and Eyjafjallajökull return `True` to this condition. This is great, but what if we want to return the actual rows? We can use @lst-bool as a **mask** to then query the rows using `.loc`.\n\n```{python}\n#| lst-label: lst-bool-query\n#| lst-cap: Query data using a boolean mask\n\nmask = df['VEI'] == 4 # Create a mask\ndf.loc[mask] # Query the data\n\n# Or, as a one line alternative:\ndf.loc[df['VEI'] == 4]\n```\n\n::: {.callout-note}\n## Question\n\nWhat volcanoes have a VEI of 5?\n\n```{python}\n#| echo: false\nmcq({\n    'La Soufrière and Calbuco' : 0,\n    'Merapi and Agung' : 0,\n    'Nyiragongo and Taal' : 0,\n    'St. Helens and El Chichón' : 1\n})\n```\n\nHow many volcanoes are in the southern hemisphere? (hint: use the `df.shape` function to count them).\n\n```{python}\n#| echo: false\nmcq({\n    '1': 0,\n    '2': 0,\n    '4': 0,\n    '6': 1,\n    '12': 0\n})\n```\n\n:::\n\n\n##### String comparisons {.unnumbered}\n\nWe can also use comparison operators on columns containing **strings** (see @cau-dtypes for caveats). @lst-str-comp illustrates a basic string comparison using the `=` operator. @tbl-comparison-str shows additional operators for strings.\n\n```{python}\n#| lst-label: lst-str-comp\n#| lst-cap: Basic comparison operation on strings\n\n\ndf.loc[df['Country'] == 'Indonesia']\n```\n\n| Operation         | Example                                 | Description                                         |\n|-------------------|-----------------------------------------|-----------------------------------------------------|\n| Contains          | `df['Name'].str.contains('Soufrière')`  | Checks if each string contains a substring          |\n| Startswith        | `df['Name'].str.startswith('E')`        | Checks if each string starts with a substring       |\n| Endswith          | `df['Name'].str.endswith('o')`          | Checks if each string ends with a substring         |\n\n\n: Common string comparison operations. {#tbl-comparison-str .striped   }\n\n\n::: {#cau-dtypes .callout-caution collapse=\"true\"}\n## Compare what is comparable!\n\nWhen using the comparison operators in @tbl-comparison-operators, we need to make sure that we are comparing data that have the **same type**. In @lst-bool, we are comparing the column `VEI` with an integer number. You can check the data type of a DataFrame using `df.dtypes`. \n\nNot all comparison operators work with all data type. For instance, you can test if a column contains a specific string using the `==` or `!=` operators, but the other won't work as they are *illogical*.\n:::\n\n#### Logical operators {.unnumbered}\n\nBut what if we want to create more complex filters based on different rules? We can use **logical operators** to combine several comparison operators. Going back to the example in @lst-basic-bool, @tbl-logical-operators illustrates the use of logical operators.\n\n| Operator | Meaning                 | Example                        | Result      |\n|----------|-------------------------|--------------------------------|-------------|\n| `&`      | Logical AND             | `(a > 1) & (b < 3)`            | `False`     |\n| `|`      | Logical OR              | `(a == 1) | (b == 1)`           | `True`      |\n| `~`      | Logical NOT             | `~(a == 1)`                    | `False`     |\n\n: Logical operators in pandas for combining boolean conditions. Use parentheses around each condition. {#tbl-logical-operators .striped }\n\nLet's gather all volcanoes that have a VEI of 3 and are in Indonesia:\n\n```{python}\n#| lst-label: lst-logical-query\n#| lst-cap: Complex filtering using logical operators\n\nmask = (df['VEI'] == 3) & (df['Country'] == 'Indonesia') # Create a mask - don't forget parentheses!\ndf.loc[mask] # Query the data\n\n```\n\n::: {.callout-note}\n## Question\n\nHow many volcanoes are either in Chile **or** in the USA?\n\n```{python}\n#| echo: false\nmcq({\n    '1': 0,\n    '3': 0,\n    '5': 1,\n    '8': 0\n})\n```\n\nHow many volcanoes are in the southern hemisphere **and** have a VEI≥4?\n\n```{python}\n#| echo: false\nmcq({\n    '1': 0,\n    '2': 1,\n    '8': 0,\n    '12': 0\n})\n```\n\n:::\n\n\n\n### Rearranging data {.unnumbered}\n\n#### Sorting data {.unnumbered}\n\nThe main function to sort data is `.sort_values` ([doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html)). It is necessary to review how *three arguments* can alter the function's behaviour:\n\n1. `by`: First argument (required) is the label of index/row used to sort the data. It is possible to sort by multiple columns by passing a list of values.\n2. `axis`: Specifies whether sorting rows (`axis = 0` - in which case `by` is a column name) or sorting columns (`axis = 1`, in which case `by` is an index value). The documentation specifies `axis = 0`, which means that rows will be sorted if `axis` is not specified.\n3. `ascending`: Using a *bool* (remember, this is a True/False behaviour), specifies if values are sorted in *ascending* (`ascending = True`, default behaviour is not specified) or *descending* (`ascending = False`) order.\n\n\n```{python}\n#| lst-label: lst-sort\n#| lst-cap: Basic sorting operations\n#| eval: false\n\ndf.sort_values('VEI') # Sort volcanoes by VEI in ascending number\ndf.sort_values('Date', ascending=False) # Sort volcanoes by eruption dates from recent to old\ndf.sort_values('Country') # .sort_values also work on strings to sort alphabetically\ndf.sort_values(['Latitude', 'Longitude']) # Sorting using multiple columns\n```\n\n\n::: {.callout-note}\n## Question\n\nAfter sorting the data in **descending order** by VEI and time, what are the three first volcanoes?\n\n```{python}\n#| echo: false\nmcq({\n    'Nyiragongo, Ontake, Kīlauea': 0,\n    'Kīlauea, Ontake, Nyiragongo': 0,\n    'Pinatubo, El Chichon, St Helens': 1,\n    'St Helens, El Chichon, Pinatubo': 0\n})\n```\n:::\n\n\n\n### Operations {.unnumbered}\n\nLet's now see how we can manipulate and operate on data contained within our DataFrame. @tbl-op-arith and @tbl-op-str respectively illustrate arithmetic and string-based operators that can be applied on parts of the DataFrame.\n\n\n#### Numeric operations {.unnumbered}\n\n@lst-op1 Illustrates how to half the VEI column save the results to a new column.\n\n```{python}\n#| lst-label: lst-op1\n#| lst-cap: Divide VEI by two and save the results to a new column.\n\ndf['VEI_halved'] = df['VEI'] / 2\n\n```\n\n::: {.callout-note}\n## Exercise\n\nLongitudes are expressed as degrees E (i.e., from 0–180 ) and degrees W (i.e., from -180–0). Use operators to convert longitudes to degrees E (i.e., from 0–360) and store the results to a column called `Longitude_E`. To do so:\n\n1. Define a mask where Longitudes are negative using [logical operators]\n2. Where the mask is `True` (i.e. where the longitude is negative), add the longitude (or subtract its absolute value) to 360\n\n\n::: {.callout-tip collapse=\"true\"}\n## Define a mask\nStart by defining a mask\n\n::: {.callout-tip collapse=\"true\"}\n## How?\n\n```python\nmask = df['Longitude'] <= 0\n```\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Select the values\nSelect the values using `.loc` and do the maths.\n\n::: {.callout-tip collapse=\"true\"}\n## How?\n\n```python\n360 + df.loc[mask, 'Longitude']\n```\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Store back the values\n\n```python\ndf.loc[mask, 'Longitude_E'] = 360 + df.loc[mask, 'Longitude']\n```\n:::\n\n\n:::\n\n| Operation      | Symbol | Example                | Description                                 |\n|----------------|--------|------------------------|---------------------------------------------|\n| Addition       | `+`    | `df['VEI'] + 1`        | Adds a value to each element                |\n| Subtraction    | `-`    | `df['VEI'] - 1`        | Subtracts a value from each element         |\n| Multiplication | `*`    | `df['VEI'] * 2`        | Multiplies each element by a value          |\n| Division       | `/`    | `df['VEI'] / 2`        | Divides each element by a value             |\n| Exponentiation | `**`   | `df['VEI'] ** 2`       | Raises each element to a power              |\n| Modulo         | `%`    | `df['VEI'] % 2`        | Remainder after division for each element   |\n\n: Common arithmetic operations on numerical pandas columns. {#tbl-op-arith .striped   }\n\n\n\n#### String operations {.unnumbered}\n\n\n\n| Operation         | Example                                 | Description                                         |\n|-------------------|-----------------------------------------|-----------------------------------------------------|\n| Concatenation     | `df['Country'] + ' volcano'`            | Adds a string to each element                       |\n| String length     | `df['Country'].str.len()`                  | Returns the length of each string                   |\n| Uppercase         | `df['Country'].str.upper()`             | Converts each string to uppercase                   |\n| Lowercase         | `df['Country'].str.lower()`             | Converts each string to lowercase                   |\n| Replace           | `df['Country'].str.replace('USA', 'US')`| Replaces substrings in each string                  |\n\n: Common string operations on pandas columns. {#tbl-op-str .striped   }"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../custom.css","../assets/webex.css"],"include-after-body":["../assets/webex.js"],"embed-resources":true,"output-file":"pandas1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","bibliography":["../references.bib"],"theme":{"light":"cosmo"},"backgroundcolor":"#F5F5F5","title":"Intro to Pandas","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}